{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best images from the Generative VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.distributions as dist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from src.generative.model import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the Observation Data\n",
    "obs_dataset = 'Data/Ferguson_fire_obs.npy' \n",
    "obs_dataset = np.load(obs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Code for the ghost structure\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, input_image_dims, latent_dims, hidden_layers, activation=nn.ReLU, device=\"cpu\"):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # inputs.\n",
    "#         self.input_image_dims = input_image_dims\n",
    "#         self.c, self.h, self.w = input_image_dims\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.latent_dims = latent_dims\n",
    "#         self.device = device\n",
    "#         self.activation = activation\n",
    "#         self.distribution = torch.distributions.Normal(0, 1)\n",
    "\n",
    "#         # encoder layers.\n",
    "#         modules = []\n",
    "#         previous_dim = self.c * self.h * self.w\n",
    "#         for h_dim in hidden_layers:\n",
    "#             modules.append(nn.Linear(previous_dim, h_dim))\n",
    "#             modules.append(activation())\n",
    "#             previous_dim = h_dim\n",
    "#         self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "#         self._mu = nn.Linear(hidden_layers[-1], self.latent_dims)\n",
    "#         self._logvar = nn.Linear(hidden_layers[-1], self.latent_dims)\n",
    "\n",
    "#         # decoder layers.\n",
    "#         modules = []\n",
    "#         current_dim = self.latent_dims\n",
    "#         for h_dim in reversed(hidden_layers):\n",
    "#             modules.append(nn.Linear(current_dim, h_dim))\n",
    "#             modules.append(activation())\n",
    "#             current_dim = h_dim\n",
    "        \n",
    "#         modules.append(nn.Linear(hidden_layers[0], self.c * self.h * self.w))\n",
    "#         modules.append(nn.Sigmoid())\n",
    "#         self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "#     def encode(self, x):\n",
    "#         \"\"\"\"\"\"\n",
    "#         return self.encoder(x)\n",
    "    \n",
    "#     def decode(self, x):\n",
    "#         \"\"\"\"\"\"\n",
    "#         return self.decoder(x)   \n",
    "\n",
    "#     def sample_latent_space(self, mu, logvar):\n",
    "#         \"\"\"\"\"\"\n",
    "#         sigma = torch.exp(0.5 * logvar)  # stability trick.\n",
    "#         z = mu +  sigma * self.distribution.sample(mu.shape).to(self.device)\n",
    "#         kl_div = (sigma**2 + mu**2 - torch.log(sigma) - 0.5).sum()\n",
    "#         return z, kl_div\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\"\"\"\n",
    "#         encoded = self.encode(x.view(x.size(0), -1))  # make sure its 1D.\n",
    "        \n",
    "#         # get mu and logvar from latent space.\n",
    "#         mu = self._mu(encoded)\n",
    "#         logvar = self._logvar(encoded)\n",
    "        \n",
    "#         # reparamaterise trick.\n",
    "#         z, kl_div = self.sample_latent_space(mu, logvar)\n",
    "\n",
    "#         decoded = self.decode(z).view(-1, self.c, self.h, self.w)\n",
    "        \n",
    "#         return decoded, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = VAE(input_image_dims=(1, 256, 256),\n",
    "            hidden_layers=[512, 256, 128],\n",
    "            latent_dims=16,\n",
    "            activation=nn.ReLU,\n",
    "            device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load state dictionary into the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print the model to confirm it's loaded correctly\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:1366\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1366\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1367\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1368\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1371\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 381\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:274\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 274\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dsml4p/lib/python3.11/site-packages/torch/serialization.py:258\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    255\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    259\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    260\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    261\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    262\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Load in the model\n",
    "model_path = 'VAE_1024_128_bs32_lr001_ld16.pt'\n",
    "\n",
    "# Load the model state dictionary with map_location to handle the CPU-only environment\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load state dictionary into the model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Print the model to confirm it's loaded correctly\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=65536, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (_mu): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (_logvar): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=65536, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load in the model\n",
    "model_path = 'VAE_1024_128_bs32_lr001_ld16.pt'\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = VAE(input_image_dims=(1, 256, 256),\n",
    "            hidden_layers=[1024, 128],\n",
    "            latent_dims=16,\n",
    "            activation=nn.ReLU,\n",
    "            device=device).to(device)\n",
    "\n",
    "# Load the model state dictionary with map_location to handle the CPU-only environment\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# # Load state dictionary into the model\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(\n",
    "        torch.load(model_path, map_location=torch.device(device))[\"model_state_dict\"]\n",
    "    )\n",
    "\n",
    "# Print the model to confirm it's loaded correctly\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Define the data_assimilation function\n",
    "def best_obs_mse_image(autoencoder, obs_dataset_path, num_generated=500, latent_dim=32, device='cpu'):\n",
    "    \"\"\"\n",
    "    Perform data assimilation using a pre-trained VAE.\n",
    " \n",
    "    Args:\n",
    "        autoencoder (nn.Module): The pre-trained VAE model.\n",
    "        background_dataset_path (str): Path to the file containing background images.\n",
    "        num_generated (int): Number of images to generate from the latent space.\n",
    "        latent_dim (int): Dimension of the latent space.\n",
    "        device (str): The device to run the model on ('cpu' or 'cuda').\n",
    " \n",
    "    Returns:\n",
    "        lowest_mse (float): The lowest MSE value found.\n",
    "        best_generated_image (np.ndarray): The generated image with the lowest MSE.\n",
    "        best_background_image (np.ndarray): The background image with the lowest MSE.\n",
    "        best_background_index (int): The index of the background image with the lowest MSE.\n",
    "    \"\"\"\n",
    "    autoencoder = autoencoder.to(device)\n",
    "    autoencoder.eval()\n",
    " \n",
    "    # Load the background images\n",
    "    obs_images = np.load(obs_dataset_path)\n",
    "    obs_images = obs_images.squeeze()  # Ensure images have correct dimensions\n",
    " \n",
    "    # Generate images from latent space\n",
    "    z = torch.randn(num_generated, latent_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_images = autoencoder.decoder(z).cpu().numpy()\n",
    " \n",
    "    # Initialize variables to store the lowest MSE and corresponding images\n",
    "    lowest_mse = float('inf')\n",
    "    best_generated_image = None\n",
    "    best_obs_image = None\n",
    "    best_obs_index = None\n",
    " \n",
    "    # Iterate through generated images and compare with background images\n",
    "    for i in range(num_generated):\n",
    "        generated_image = generated_images[i].squeeze()\n",
    " \n",
    "        for j in range(len(obs_images)):\n",
    "            obs_image = obs_images[j].squeeze()\n",
    " \n",
    "            # Compute MSE\n",
    "            mse = mean_squared_error(obs_image, generated_image)\n",
    " \n",
    "            # Update the lowest MSE and corresponding images\n",
    "            if mse < lowest_mse:\n",
    "                lowest_mse = mse\n",
    "                best_generated_image = generated_image\n",
    "                best_obs_image = obs_image\n",
    "                best_obs_index = j\n",
    " \n",
    "    # Plot the best matching images\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(best_generated_image, cmap='viridis')\n",
    "    ax[0].set_title(\"Best Generated Image\")\n",
    "    ax[0].axis('off')\n",
    " \n",
    "    ax[1].imshow(best_obs_image, cmap='viridis')\n",
    "    ax[1].set_title(\"Best Observation Image\")\n",
    "    ax[1].axis('off')\n",
    " \n",
    "    plt.show()\n",
    " \n",
    "    return lowest_mse, best_generated_image, best_obs_image, best_obs_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml4p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
